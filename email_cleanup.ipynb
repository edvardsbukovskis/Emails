{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os \n",
    "import re\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(r'C:\\Users\\ebukovs0\\Documents\\email_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "922337203"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxInt = sys.maxsize\n",
    "maxInt = int(maxInt/10000000000)\n",
    "csv.field_size_limit(maxInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 9298: unexpected end of data\n",
      "Skipping line 21: unexpected end of data\n",
      "Skipping line 22348: unexpected end of data\n",
      "Skipping line 14834: unexpected end of data\n",
      "Skipping line 14314: unexpected end of data\n",
      "Skipping line 12744: unexpected end of data\n",
      "Skipping line 18250: unexpected end of data\n",
      "Skipping line 285: unexpected end of data\n",
      "Skipping line 3939: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "d1 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\10-440-400.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d2 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\11-400-360.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d3 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\12-360-320.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d4 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\13-320-280.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d5 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\14-280-240.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d6 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\15-240-200.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d7 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\16-200-150.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d8 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\17-150-100.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d9 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\18-100-50.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d10 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\19-50-0-END.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d11 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\3-720-700.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d12 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\4-700-660.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d13 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\5-660-620.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d14 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\6-620-580.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d15 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\7-580-530.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d16 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\8-530-480.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n",
    "d17 = pd.read_csv(r'C:\\Users\\ebukovs0\\Documents\\email_files\\9-480-440.csv', sep=';', header=None, engine='python', encoding=\"utf-8-sig\", error_bad_lines=False, usecols=[1,17,11,24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [17,24], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop invalid rows\n",
    "df = df[df[17].str.contains('@')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset column and row indexes\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.columns = range(df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete bussinesses\n",
    "private_list = ['gmail.com', 'inbox.lv', 'mail.ru', 'bk.ru', 'apollo.lv', 'hotmail.com', 'zb.lv', 'yahoo.com', 'tet.lv', 'lattelecom.lv']\n",
    "df = df[df[2].str.contains('|'.join(private_list), case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part finds tet questions from templates phrases in dataframe\n",
    "\n",
    "#initialize set of template questions or phrases\n",
    "template_list = ['klienta numuru vai personas kodu', 'klienta numuru vai > personas kodu', 'nepiecie≈°ami klienta dati']\n",
    "\n",
    "dftest = df[df[3].str.contains('|'.join(template_list), case =True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select emails only from tet which have key phrases (emails from tet)\n",
    "l = ['tet.lv','lattelecom.lv']\n",
    "dftest = dftest[dftest[2].str.contains('|'.join(l), case = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with client questions (Includes unecessary infromation) step1\n",
    "dfclean = dftest[3].str.split('|'.join(template_list)).str[1]\n",
    "dfclean = dfclean.str.split('--Original Message--').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get questions from clients here (unecessary information cleanaed) (NOT 100%) step2\n",
    "dfclean_q2 = dfclean.str.split('Subject:').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter off emails with subjects in text\n",
    "dfclean_q3 = dfclean_q2.str.split('    ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes for easier cleanup later\n",
    "dfclean_q2_f = dfclean_q2.to_frame()\n",
    "dfclean_q3_f = dfclean_q3.to_frame() \n",
    "\n",
    "#join frames and append cleaning\n",
    "final_clean = dfclean_q2_f.join(dfclean_q3_f, lsuffix = '_3', how = 'inner')\n",
    "final_clean = final_clean['3'].fillna(final_clean['3_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean= final_clean.to_frame()\n",
    "nan_value = float(\"NaN\")\n",
    "final_clean.replace(\"\", nan_value, inplace = True)\n",
    "final_clean.replace(\" \", nan_value, inplace = True)\n",
    "final_clean.replace(\"  \", nan_value, inplace = True)\n",
    "final_clean.replace(\"   \", nan_value, inplace = True)\n",
    "final_clean.dropna(subset = ['3'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove emails\n",
    "final_clean['3'] = final_clean['3'].str.replace('\\S*@\\S*\\s?', '')\n",
    "#remove links\n",
    "final_clean['3'] = final_clean['3'].str.replace('http\\S+', '')\n",
    "\n",
    "#All to lower\n",
    "final_clean['3'] = final_clean['3'].str.lower()\n",
    "\n",
    "#remove all kinds of symbols\n",
    "final_clean['3'] = final_clean['3'].str.replace(',', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('.', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('+', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('-', '')\n",
    "\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace('≈õ','s')\n",
    "final_clean['3'] = final_clean['3'].str.replace('≈°','s')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒ´','i')\n",
    "final_clean['3'] = final_clean['3'].str.replace('≈´', 'u')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒç', 'c')\n",
    "final_clean['3'] = final_clean['3'].str.replace('≈Ü', 'n')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒ∑', 'k')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒì', 'e')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒÅ','a')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒ£', 'g')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ƒº', 'l')\n",
    "final_clean['3'] = final_clean['3'].str.replace('≈æ', 'z')\n",
    "final_clean['3'] = final_clean['3'].str.replace('√©', 'e')\n",
    "final_clean['3'] = final_clean['3'].str.replace('√≠', 'i')\n",
    "final_clean['3'] = final_clean['3'].str.replace('√∫', 'u')\n",
    "final_clean['3'] = final_clean['3'].str.replace('√§', 'a')\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace('üòÅ', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('üò†', '')\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace('ee', 'e')\n",
    "final_clean['3'] = final_clean['3'].str.replace('aa', 'a')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ii', 'i')\n",
    "final_clean['3'] = final_clean['3'].str.replace('uu', 'u')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ee', 'e')\n",
    "final_clean['3'] = final_clean['3'].str.replace('sh', 's')\n",
    "final_clean['3'] = final_clean['3'].str.replace('lj', 'l')\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace(' uz ', ' ')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' no ', ' ')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' ja ', ' ')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' ko ', ' ')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' ap ', ' ')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' ir ', ' ')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' un ', ' ')\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace(' lv', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('lv ', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('labdien', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('labvakar', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('sveiki', '')\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace('re:', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('re ', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('fwd:', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('fw', '')\n",
    "\n",
    "final_clean['3'] = final_clean['3'].str.replace('!', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace(',', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('.', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('?', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('/', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('(', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace(')', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('[', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace(']', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('‚Äì', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('-', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('+', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('/', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('|', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('<', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('>', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('=', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('%', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('#', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('$', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('^', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('&', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('_', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('@', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('*', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace(':', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('\"', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('‚Ç¨', '')\n",
    "\n",
    "#remove non-latin letters\n",
    "final_clean['3'] = final_clean['3'].str.replace('[^\\x00-\\x7F]+', '')\n",
    "\n",
    "#remove numbers and single chars and whitespaces\n",
    "final_clean['3'] = final_clean['3'].str.replace('[0-9]', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace(' +', ' ')\n",
    "#exception case\n",
    "final_clean['3'] = final_clean['3'].str.replace('Ar cienu.+', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('ar cienu.+', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('reply to mess.+', '')\n",
    "\n",
    "#remove lone characters\n",
    "final_clean['3'] = final_clean['3'].str.replace('(^| ).( |$)', '')\n",
    "\n",
    "#remove more numbers and whitespaces\n",
    "final_clean['3'] = final_clean['3'].str.replace('^\\s+|\\s+$', '')\n",
    "final_clean['3'] = final_clean['3'].str.replace('\\s\\s+', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Aplikacijas\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Aplikacijas\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Aplikacijas\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#remove empty rows (again after cleaning)\n",
    "final_clean['3'].replace('', np.nan, inplace=True) #replace empty strings witn NaN\n",
    "final_clean.dropna(subset=['3'], inplace=True)\n",
    "#remove rows where word count is small\n",
    "count = final_clean['3'].str.split().str.len()\n",
    "~(count == 1)\n",
    "final_clean = final_clean[~(count == 1)]\n",
    "final_clean = final_clean[~(count == 2)]\n",
    "final_clean = final_clean[~(count == 3)]\n",
    "final_clean = final_clean[~(count == 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean = final_clean[~final_clean['3'].str.contains('surogatpasts')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sakiet ludzu vai iespejams parlikt rekina terminu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>par apmaksukada bus apmaksa par hulio lietosanu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>nu jau vesela darba diena pagajusi kops vakar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>nu jau vesela darba diena pagajusi kops vakar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>sveicinati sortcutpakalpojums praktiski nav iz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239286</th>\n",
       "      <td>jautajums saistiba ar bojajumu jautajuma veids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239359</th>\n",
       "      <td>jautajums par pakalpojuma lietosanu jautajuma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239409</th>\n",
       "      <td>jautajums par rekinu jautajuma veids rekins kl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239504</th>\n",
       "      <td>jau tik iss apmaksas terminstad jau jus varetu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239526</th>\n",
       "      <td>kluda rekina tika sanemts rekins par jusu snie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1507 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        3\n",
       "31      sakiet ludzu vai iespejams parlikt rekina terminu\n",
       "37        par apmaksukada bus apmaksa par hulio lietosanu\n",
       "126     nu jau vesela darba diena pagajusi kops vakar ...\n",
       "151     nu jau vesela darba diena pagajusi kops vakar ...\n",
       "156     sveicinati sortcutpakalpojums praktiski nav iz...\n",
       "...                                                   ...\n",
       "239286  jautajums saistiba ar bojajumu jautajuma veids...\n",
       "239359  jautajums par pakalpojuma lietosanu jautajuma ...\n",
       "239409  jautajums par rekinu jautajuma veids rekins kl...\n",
       "239504  jau tik iss apmaksas terminstad jau jus varetu...\n",
       "239526  kluda rekina tika sanemts rekins par jusu snie...\n",
       "\n",
       "[1507 rows x 1 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean.to_excel('cleaned_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clean = final_clean.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Labdien Nu jau vesela darba diena pagajusi kops vakar pieteiktajam 4 jaunam kanalu paketem Kad tas tiks aktivizetas   Ar cienu   Juris Bulans'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_clean[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ML PART #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Aplikacijas\\Anaconda\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-2d5275623551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPool1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Aplikacijas\\Anaconda\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Dropout\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPool1D, LSTM\n",
    "from keras.prepocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
